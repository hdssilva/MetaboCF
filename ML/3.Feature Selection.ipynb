{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from aux_functions.name_2lines import name_2lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b685f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed\n",
    "seed=41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad32ee",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ee94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pickle.load(open('Dataset/feature_names.pkl', 'rb'))\n",
    "X_train = pickle.load(open(f'Dataset/X_train.pkl', 'rb'))\n",
    "y_train = pickle.load(open(f'Dataset/y_train.pkl', 'rb'))\n",
    "sc_u = pickle.load(open(f'Dataset/SC_wunique_child.pkl', 'rb'))\n",
    "c_u = pickle.load(open(f'Dataset/C_wunique_child.pkl', 'rb'))\n",
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11cec08",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!!!! Resets feature selection file\n",
    "#pickle.dump({}, open('Results/selected_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09346e2e",
   "metadata": {},
   "source": [
    "## Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96196695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = X_train\n",
    "y_train_ = y_train[:, 0]\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(random_state = seed), threshold=1e-5)\n",
    "sel.fit(X_train_, y_train_)\n",
    "importances = sel.estimator_.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in sel.estimator_.estimators_], axis=0)\n",
    "mdi_f = sel.get_feature_names_out(feature_names)\n",
    "mdi_f = list(mdi_f)\n",
    "print('Important features:', mdi_f)\n",
    "\n",
    "f_index = [feature_names.index(feature) for feature in mdi_f]\n",
    "cor_matrix = pd.DataFrame(X_train[:, f_index], columns=mdi_f).corr(method='spearman').abs()\n",
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "sel_f = [f for f in mdi_f if f not in to_drop]\n",
    "print('To drop:', to_drop)\n",
    "print('Selected features:', sel_f)\n",
    "\n",
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "feat_dic['Kingdom'] = {'Chemical entities': {'MDI': {'importances': importances, 'std': std, 'selected features':mdi_f}, \n",
    "                                      'correlation (to drop)': to_drop, 'selected features': sel_f}}\n",
    "pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60431aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = feat_dic['Kingdom']['Chemical entities']['MDI']['importances']\n",
    "std = feat_dic['Kingdom']['Chemical entities']['MDI']['std']\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "forest_importances.plot.barh(xerr=std, ax=ax)\n",
    "plt.gca().invert_yaxis()\n",
    "ax.set_title(\"Feature importance using MDI\",size=25)\n",
    "ax.set_xlabel(\"Mean decrease in impurity\", size=20)\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(12, 25)\n",
    "plt.savefig(f'Plots/FeatureImportance/Kingdom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde86f5",
   "metadata": {},
   "source": [
    "## Superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "kings = np.unique(y_train[:,0])\n",
    "for i, king in enumerate(kings):\n",
    "    print(i, king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "feat_dic['Superclass'] = {}\n",
    "pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))\n",
    "\n",
    "for i, king in enumerate(kings):\n",
    "    print(i, king)\n",
    "    X_train_ = X_train[y_train[:,0] == king, :]\n",
    "    y_train_ = y_train[y_train[:,0] == king, :][:, 1]\n",
    "    \n",
    "    sel = SelectFromModel(RandomForestClassifier(random_state = seed), threshold=1e-5)\n",
    "    sel.fit(X_train_, y_train_)\n",
    "    importances = sel.estimator_.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in sel.estimator_.estimators_], axis=0)\n",
    "    mdi_f = sel.get_feature_names_out(feature_names)\n",
    "    mdi_f = list(mdi_f)\n",
    "    print('Important features:', mdi_f)\n",
    "    \n",
    "    f_index = [feature_names.index(feature) for feature in mdi_f]\n",
    "    cor_matrix = pd.DataFrame(X_train[:, f_index], columns=mdi_f).corr(method='spearman').abs()\n",
    "    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "    sel_f = [f for f in mdi_f if f not in to_drop]\n",
    "    print('To drop:', to_drop)\n",
    "    print('Selected features:', sel_f)\n",
    "    \n",
    "    feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "    feat_dic['Superclass'][king] = {'MDI': {'importances': importances, 'std': std, 'selected features':mdi_f}, \n",
    "                                      'correlation (to drop)': to_drop, 'selected features': sel_f}\n",
    "    pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i, king in enumerate(kings):\n",
    "    feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "    importances = feat_dic['Superclass'][king]['MDI']['importances']\n",
    "    std = feat_dic['Superclass'][king]['MDI']['std']\n",
    "    plt.style.use('seaborn-notebook')\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    forest_importances.plot.barh(xerr=std, ax=ax)\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.set_title(f\"Feature importance using MDI\\n({king})\",size=25)\n",
    "    ax.set_xlabel(\"Mean decrease in impurity\", size=20)\n",
    "    fig.tight_layout()\n",
    "    fig.set_size_inches(12, 25)\n",
    "    plt.savefig(f'Plots/FeatureImportance/Superclass_{i}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194777e",
   "metadata": {},
   "source": [
    "### Binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sclasses_bin = {king:np.unique(y_train[y_train[:,0]==king][:, 1]) for king in np.unique(y_train[:,0])}\n",
    "for king, sclasses in sclasses_bin.items():\n",
    "    print(king, sclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81304347",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "feat_dic['Superclass_binary'] = {}\n",
    "pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))\n",
    "\n",
    "for king, sclasses in sclasses_bin.items():\n",
    "    print(king)\n",
    "    for i, sclass in enumerate(sclasses):\n",
    "        print(i, sclass)\n",
    "        X_train_ = X_train[y_train[:,0] == king, :]\n",
    "        y_train_ = y_train[y_train[:,0] == king, :][:, 1]\n",
    "        X_train_ = np.append(X_train_[y_train_ == sclass, :], X_train_[y_train_ != sclass, :], axis=0)\n",
    "        y_train_ = [*[1]*len(y_train_[y_train_ == sclass]), *[0]*len(y_train_[y_train_ != sclass])]\n",
    "        y_train_ = np.array(y_train_)\n",
    "    \n",
    "        sel = SelectFromModel(RandomForestClassifier(random_state = seed), threshold=1e-5)\n",
    "        sel.fit(X_train_, y_train_)\n",
    "        importances = sel.estimator_.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in sel.estimator_.estimators_], axis=0)\n",
    "        mdi_f = sel.get_feature_names_out(feature_names)\n",
    "        mdi_f = list(mdi_f)\n",
    "        print('Important features:', mdi_f)\n",
    "\n",
    "        f_index = [feature_names.index(feature) for feature in mdi_f]\n",
    "        cor_matrix = pd.DataFrame(X_train[:, f_index], columns=mdi_f).corr(method='spearman').abs()\n",
    "        upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "        to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "        sel_f = [f for f in mdi_f if f not in to_drop]\n",
    "        print('To drop:', to_drop)\n",
    "        print('Selected features:', sel_f)\n",
    "\n",
    "        feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "        feat_dic['Superclass_binary'][sclass] = {'MDI': {'importances': importances, 'std': std, 'selected features':mdi_f}, \n",
    "                                          'correlation (to drop)': to_drop, 'selected features': sel_f}\n",
    "        pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e15753",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for king, sclasses in sclasses_bin.items():\n",
    "    print(king)\n",
    "    for i, sclass in enumerate(sclasses):\n",
    "        print(i, sclass)\n",
    "        feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))['Superclass_binary'][sclass]['MDI']\n",
    "        importances = feat_dic['importances']\n",
    "        std = feat_dic['std']\n",
    "        plt.style.use('seaborn-notebook')\n",
    "        forest_importances = pd.Series(importances, index=feature_names)\n",
    "        fig, ax = plt.subplots(dpi=300)\n",
    "        forest_importances.plot.barh(xerr=std, ax=ax)\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax.set_title(f\"Feature importance using MDI\\n(Binary Superclass - {sclass})\",size=25)\n",
    "        ax.set_xlabel(\"Mean decrease in impurity\", size=20)\n",
    "        fig.tight_layout()\n",
    "        fig.set_size_inches(12, 25)\n",
    "        plt.savefig(f'Plots/FeatureImportance/Kingdom={king}_Binary_Superclass={i}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf9e32",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f457d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sclasses = np.unique(y_train[:,1])\n",
    "for i, sclass in enumerate(sclasses):\n",
    "    if sclass in sc_u:\n",
    "        continue\n",
    "    print(i, sclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "feat_dic['Class'] = {}\n",
    "pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))\n",
    "\n",
    "for i, sclass in enumerate(sclasses):\n",
    "    if sclass in sc_u:\n",
    "        continue\n",
    "    print(i, sclass)\n",
    "    \n",
    "    X_train_ = X_train[y_train[:,1] == sclass, :]\n",
    "    y_train_ = y_train[y_train[:,1] == sclass, :][:, 2]\n",
    "    \n",
    "    sel = SelectFromModel(RandomForestClassifier(random_state = seed), threshold=1e-5)\n",
    "    sel.fit(X_train_, y_train_)\n",
    "    importances = sel.estimator_.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in sel.estimator_.estimators_], axis=0)\n",
    "    mdi_f = sel.get_feature_names_out(feature_names)\n",
    "    mdi_f = list(mdi_f)\n",
    "    print('Important features:', mdi_f)\n",
    "    \n",
    "    f_index = [feature_names.index(feature) for feature in mdi_f]\n",
    "    cor_matrix = pd.DataFrame(X_train[:, f_index], columns=mdi_f).corr(method='spearman').abs()\n",
    "    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "    sel_f = [f for f in mdi_f if f not in to_drop]\n",
    "    print('To drop:', to_drop)\n",
    "    print('Selected features:', sel_f, '\\n')\n",
    "    \n",
    "    feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "    feat_dic['Class'][sclass] = {'MDI': {'importances': importances, 'std': std, 'selected features':mdi_f}, \n",
    "                                      'correlation (to drop)': to_drop, 'selected features': sel_f}\n",
    "    pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i, sclass in enumerate(sclasses):\n",
    "    if sclass in sc_u:\n",
    "        continue\n",
    "    feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "    importances = feat_dic['Class'][sclass]['MDI']['importances']\n",
    "    std = feat_dic['Class'][sclass]['MDI']['std']\n",
    "    plt.style.use('seaborn-notebook')\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    forest_importances.plot.barh(xerr=std, ax=ax)\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.set_title(f\"Feature importance using MDI\\n({sclass})\",size=25)\n",
    "    ax.set_xlabel(\"Mean decrease in impurity\", size=20)\n",
    "    fig.tight_layout()\n",
    "    fig.set_size_inches(12, 25)\n",
    "    plt.savefig(f'Plots/FeatureImportance/Class_{i}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d5aee",
   "metadata": {},
   "source": [
    "## Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c472100",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train[:,2])\n",
    "for i, class_ in enumerate(classes):\n",
    "    if class_ in c_u:\n",
    "        continue\n",
    "    print(i, class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "feat_dic['Subclass'] = {}\n",
    "pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))\n",
    "\n",
    "for i, class_ in enumerate(classes):\n",
    "    if class_ in c_u:\n",
    "        continue\n",
    "    print(i, class_)\n",
    "    \n",
    "    X_train_ = X_train[y_train[:,2] == class_, :]\n",
    "    y_train_ = y_train[y_train[:,2] == class_, :][:, 3]\n",
    "    \n",
    "    sel = SelectFromModel(RandomForestClassifier(random_state = seed), threshold=1e-5)\n",
    "    sel.fit(X_train_, y_train_)\n",
    "    importances = sel.estimator_.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in sel.estimator_.estimators_], axis=0)\n",
    "    mdi_f = sel.get_feature_names_out(feature_names)\n",
    "    mdi_f = list(mdi_f)\n",
    "    print('Important features:', mdi_f)\n",
    "    \n",
    "    f_index = [feature_names.index(feature) for feature in mdi_f]\n",
    "    cor_matrix = pd.DataFrame(X_train[:, f_index], columns=mdi_f).corr(method='spearman').abs()\n",
    "    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "    sel_f = [f for f in mdi_f if f not in to_drop]\n",
    "    print('To drop:', to_drop)\n",
    "    print('Selected features:', sel_f, '\\n')\n",
    "    \n",
    "    feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "    feat_dic['Subclass'][class_] = {'MDI': {'importances': importances, 'std': std, 'selected features':mdi_f}, \n",
    "                                      'correlation (to drop)': to_drop, 'selected features': sel_f}\n",
    "    pickle.dump(feat_dic, open('Results/selected_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i, class_ in enumerate(classes):\n",
    "    if class_ in c_u:\n",
    "        continue\n",
    "    feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "    importances = feat_dic['Subclass'][class_]['MDI']['importances']\n",
    "    std = feat_dic['Subclass'][class_]['MDI']['std']\n",
    "    plt.style.use('seaborn-notebook')\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    forest_importances.plot.barh(xerr=std, ax=ax)\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.set_title(f\"Feature importance using MDI\\n({class_})\",size=25)\n",
    "    ax.set_xlabel(\"Mean decrease in impurity\", size=20)\n",
    "    fig.tight_layout()\n",
    "    fig.set_size_inches(12, 25)\n",
    "    plt.savefig(f'Plots/FeatureImportance/Subclass_{i}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffa2ff",
   "metadata": {},
   "source": [
    "## Importance heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "importances = []\n",
    "y = []\n",
    "for classif_level, classif_name in {0:'Kingdom', 1:'Superclass', 2:'Class', 3:'Subclass'}.items():\n",
    "    if classif_level == 0:\n",
    "        importances.append(list(feat_dic[classif_name]['Chemical entities']['MDI']['importances']))\n",
    "        y.append('(Kingdom) Chemical entities')\n",
    "    else:\n",
    "        for i in np.unique(y_train[:, classif_level-1]):\n",
    "            if (i not in sc_u) and (i not in c_u):\n",
    "                importances.append(list(feat_dic[classif_name][i]['MDI']['importances']))\n",
    "                y.append(f'({classif_name}) {i}')\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 30),dpi=800)\n",
    "sns.heatmap(importances, cmap='Blues', xticklabels=feature_names, yticklabels=y, cbar_kws={\"shrink\": .40})\n",
    "ax.set_title(\"Mean Decrease in Giny Feature Importance\", fontsize=20)\n",
    "ax.set_xlabel('Features', fontsize=15)\n",
    "ax.set_ylabel('(ChemOnt level) Parent node', fontsize=15)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 6)\n",
    "plt.savefig('Plots/MDI Feature Importances', bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680806bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_w_threshold = [[] for i in range(len(y))]\n",
    "importances_w_threshold_features = []\n",
    "for j in range(len(feature_names)):\n",
    "    for i in range(len(y)):\n",
    "        if importances[i][j] >= 0.1: # threshold\n",
    "            importances_w_threshold_features.append(feature_names[j])\n",
    "            for i in range(len(y)):\n",
    "                importances_w_threshold[i].append(importances[i][j])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['xtick.labelsize'] = 16\n",
    "fig, ax = plt.subplots(figsize=(17, 30), dpi=800)\n",
    "sns.heatmap(importances_w_threshold, cmap='Blues',\n",
    "            yticklabels=y, cbar_kws={'shrink': .4, 'pad':0.02})\n",
    "ax.set_title(\"Mean Decrease in Giny Feature Importance\", fontsize=20)\n",
    "ax.set_xlabel('Features', fontsize=15)\n",
    "ax.set_xticklabels(name_2lines(importances_w_threshold_features, 10), ha='center', va='top', rotation=90)\n",
    "ax.set_ylabel('(ChemOnt level) Parent node', fontsize=15)\n",
    "plt.savefig('Plots/MDI Feature Importances (w_threshold)', bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdd9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_imp = []\n",
    "for imp_class in importances_w_threshold:\n",
    "    for rank in range(1, 11):\n",
    "        highest_value = 0\n",
    "        float_bool = False\n",
    "        for i in imp_class:\n",
    "            if i<1 and i>highest_value:\n",
    "                highest_value = i\n",
    "            if type(i) is np.float64:  #If there is float, sinalize\n",
    "                float_bool = True\n",
    "        if not float_bool:\n",
    "            #If a rank ends finding no float, means we have hit the lowest number, so this middle rank is considered the last (11)\n",
    "            imp_class = list(map(lambda i: 11 if i==rank-1 else i, imp_class))\n",
    "        imp_class = list(map(lambda i: rank if i==highest_value else i, imp_class))\n",
    "    ranked_imp.append(list(map(lambda i: 11 if type(i)!=int else i, imp_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 30), dpi=800)\n",
    "sns.heatmap(ranked_imp, cmap=sns.color_palette('Blues_r', 11, as_cmap=True), xticklabels=importances_w_threshold_features, yticklabels=y, \n",
    "            cbar_kws={\"shrink\": .40})\n",
    "ax.set_title(\"Mean Decrease in Giny Feature Importance\")\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('(ChemOnt level) Parent node')\n",
    "plt.savefig('MDI Feature Importances (Ranked)', bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c409b",
   "metadata": {},
   "source": [
    "### Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key1, value1 in feat_dic.items():\n",
    "    for key2, value2 in value1.items():\n",
    "        print(value2['correlation (to drop)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73273d",
   "metadata": {},
   "source": [
    "### Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9feab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))\n",
    "df = []\n",
    "for key1, value1 in feat_dic.items():\n",
    "    if key1 == 'Superclass_binary':\n",
    "        key1 = 'Superclass (binary classifiers)'\n",
    "    for key2, value2 in value1.items():\n",
    "        df.append({'Level':key1, 'Node':key2, 'Selected features': \", \".join(value2['selected features'])})\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv('Results/Selected_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf37a68",
   "metadata": {},
   "source": [
    "### N/C and Nitrogen correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dic = pickle.load(open('Results/selected_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1bd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in feat_dic.items():\n",
    "    for key2, value2 in value.items():\n",
    "        if len(value2['correlation (to drop)']) != 3:\n",
    "            print(key2)\n",
    "            print(value2['MDI']['selected features'])\n",
    "            print(value2['selected features'])\n",
    "            print(value2['correlation (to drop)'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=800)\n",
    "ax.plot(X_train[:, 4], X_train[:, -3], 'bo')\n",
    "ax.set_xlabel('N/C')\n",
    "ax.set_ylabel('Nitrogen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20), dpi=800)\n",
    "ax.plot(X_train[:, 0], X_train[:, 1], 'bo')\n",
    "ax.set_xlabel('Carbon')\n",
    "ax.set_ylabel('Hydrogen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20), dpi=800)\n",
    "ax.plot(X_train[:, -15], X_train[:, 0], 'bo')\n",
    "ax.set_xlabel('Mass')\n",
    "ax.set_ylabel('Carbon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20), dpi=800)\n",
    "ax.plot(X_train[:, -15], X_train[:, 1], 'bo')\n",
    "ax.set_xlabel('Mass')\n",
    "ax.set_ylabel('Hydrogen')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
